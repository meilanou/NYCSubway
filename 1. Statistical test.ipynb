{
 "metadata": {
  "name": "",
  "signature": "sha256:dfc02c08dea190f29323c27994a82c2ac653dada96ede58cc20810b6fc0b1f4a"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Analyze rain vs. ridership with statistical tests"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Statistical tests can help us to obtain statistical rigor in comparing and evaluating data. Here I'm running a few tests on ridership data of raining and non-raining day, to validate the distribution and statistical significance.<br/>\n",
      "<ul>\n",
      "    <li>Normality</li>\n",
      "    <li>Equal means</li>\n",
      "    <li>Same populations</li>\n",
      "</ul>"
     ]
    },
    {
     "cell_type": "heading",
     "level": 6,
     "metadata": {},
     "source": [
      "First import libraries for mathematical operations and plotting, and initialize global variables."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import pandas as pd\n",
      "import scipy.stats as st\n",
      "\n",
      "df = pd.read_csv('turnstile_weather_v2.csv', parse_dates=['datetime'])\n",
      "ent_hr_rain = df[df[\"rain\"] == 1][\"ENTRIESn_hourly\"]\n",
      "ent_hr_no_rain = df[df[\"rain\"] == 0][\"ENTRIESn_hourly\"]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Normality"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "From the histograms in <a href=\"0.%20Exploring%20data.ipynb\" target=\"_blank\">section 0</a> we could already tell that ridership distribution is right-skewed. Here I'm verifying this again with the Shapiro\u2013Wilk test which is a 1-tailed test of normality in frequentist statistics. From the result p-values we can reject the null hypothesis that the data was drawn from a normal distribution for both raining and non-raining days. Both are non-normal."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "w, p = st.shapiro(ent_hr_rain)\n",
      "print 'RAIN: w = {0:.5f}, p-value = {1:.5f}'.format(w, p)\n",
      "# Got warning: p-value may not be accurate for N > 5000. Check weekdays only.\n",
      "#w, p = st.shapiro(ent_hr_no_rain)\n",
      "w, p = st.shapiro(df[(df['rain'] == 0) & (df['weekday'] == 1)]['ENTRIESn_hourly'])\n",
      "print 'NO RAIN: w = {0:.5f}, p-value = {1:.5f}'.format(w, p)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "RAIN: w = 0.59388, p-value = 0.00000\n",
        "NO RAIN: w = 0.61391, p-value = 0.00000\n"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Equal means"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<p>\n",
      "In <a href=\"0.%20Exploring%20data.ipynb\" target=\"_blank\">section 0</a> I already calcuated the basic stats of hourly entries (every 4 hours) for raining and non-raining days. The numbers are:\n",
      "</p>\n",
      "<p>\n",
      "RAIN , Count: 9,585 , Total: 19,440,259 , Median: 939 , Mean: 2,028.20<br/>\n",
      "NO RAIN , Count: 33,064 , Total: 61,020,916 , Median: 893 , Mean: 1,845.54\n",
      "</p>\n",
      "<p>\n",
      "The 2 means are not different. But what does the difference mean? Though when we perform Welch's t test, we usually assume the data is normal. With large enough sample size, we can still run Welch's t test to see if 2 data sets have the same sample means (&mu;<sub>1</sub> = &mu;<sub>2</sub>). Below the scipy ttest_ind function is run for 2-tailed t test. Converting to 1-tailed results, t-statistic is greater than 0 and p-value/2 is much less than 0.05 p-critical value. We can reject the null hypothesis that 2 independent samples have identical average (expected) values. And we can confirm that the mean of entries is higher when it rained (&mu;<sub>1</sub> &gt; &mu;<sub>2</sub>). This is interesting. From the bar chart in <a href=\"0.%20Exploring%20data.ipynb\" target=\"_blank\">section 0</a> these 2 data sets don't look too different but they are statistically different. Let's do one more test to confirm.\n",
      "</p>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "t, p = st.ttest_ind(ent_hr_rain, ent_hr_no_rain, equal_var = False)\n",
      "print 'RAIN vs. NO RAIN: t = {0:,.5f}, p-value = {1:.10f}'.format(t, p)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "RAIN vs. NO RAIN: t = 5.04288, p-value = 0.0000004641\n"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Same populations"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Mann\u2013Whitney U test is a nonparametric test of the null hypothesis that two populations are the same. Below I'm running scipy's mannwhitneyu function to see if these 2 data sets are from the same population."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "u, p = st.mannwhitneyu(ent_hr_rain, ent_hr_no_rain)\n",
      "print 'RAIN vs. NO RAIN: u = {0:,.0f}, p-value = {1:.10f}'.format(u, p)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "RAIN vs. NO RAIN: u = 153,635,120, p-value = nan\n"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "However, I can't get p-value directly using this function. So I'm calculating 1-tailed p-value maually. Here because I care more about whether these 2 samples were taken from the identical distributions, I'm doubling it for a 2-tailed p-value. The result 2-tailed p-value falls below 0.05 p-critical value. Hence we can reject the null and say that these 2 samples were taken from distinct populations."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "'''\n",
      "http://stats.stackexchange.com/questions/116315/problem-with-mann-whitney-u-test-in-scipy\n",
      "'''\n",
      "m_u = len(ent_hr_rain)*len(ent_hr_no_rain)/2\n",
      "sigma_u = np.sqrt(len(ent_hr_rain)*len(ent_hr_no_rain)*(len(ent_hr_rain)+len(ent_hr_no_rain)+1)/12)\n",
      "z = (u - m_u)/sigma_u\n",
      "p = 2*st.norm.cdf(z)\n",
      "print 'RAIN vs. NO RAIN: u = {0:,.0f}, p-value = {1:.10f}'.format(u, p)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "RAIN vs. NO RAIN: u = 153,635,120, p-value = 0.0000054827\n"
       ]
      }
     ],
     "prompt_number": 14
    }
   ],
   "metadata": {}
  }
 ]
}