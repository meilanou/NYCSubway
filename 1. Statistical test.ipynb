{
 "metadata": {
  "name": "",
  "signature": "sha256:4ee11635fd2203191d8a61826a3986c6457d2dfbc90910289c1bb270127c656d"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Analyze rain vs. ridership with statistical tests"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Statistical tests can help us to obtain statistical rigor in comparing and evaluating data. Here I'm running a few tests with &alpha; level = 0.05 on ridership data of raini and non-raini days, to validate the distribution and statistical significance.<br/>\n",
      "<ul>\n",
      "    <li>Normality</li>\n",
      "    <li>Equal means - Welch's t-test</li>\n",
      "    <li>Same populations - Mann\u2013Whitney U test</li>\n",
      "</ul>"
     ]
    },
    {
     "cell_type": "heading",
     "level": 6,
     "metadata": {},
     "source": [
      "First import libraries for mathematical operations and plotting, and initialize global variables."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import pandas as pd\n",
      "import scipy.stats as st\n",
      "\n",
      "df = pd.read_csv('turnstile_weather_v2.csv', parse_dates=['datetime'])\n",
      "ent_hr_rain = df[df[\"rain\"] == 1][\"ENTRIESn_hourly\"]\n",
      "ent_hr_no_rain = df[df[\"rain\"] == 0][\"ENTRIESn_hourly\"]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 24
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Normality"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "From the histograms in <a href=\"0.%20Exploring%20data.ipynb\" target=\"_blank\">section 0</a> we already knew that the distribution is right-skewed. To obtain statistic rigor, I'm double checking again. But because Shapiro\u2013Wilk test may not be accurate for N > 5000, here I'm testing the normality with scipy.stats.normaltest which combines skew and kurtosis normality tests. Its p-value is a 2-tail chi squared probability for the hypothesis test. From the result p-values we can reject the null hypothesis that the data was drawn from a normal distribution for both rainy and non-rainy days. Both are non-normal."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# w, p = st.shapiro(df[(df['rain'] == 0) & (df['weekday'] == 1)]['ENTRIESn_hourly'])\n",
      "# Got warning: p-value may not be accurate for N > 5000.\n",
      "k2, p = st.normaltest(ent_hr_rain)\n",
      "print 'RAIN: k2 = {0:.5f}, p-value = {1:.5f}'.format(k2, p)\n",
      "k2, p = st.normaltest(ent_hr_no_rain)\n",
      "print 'NO RAIN: k2 = {0:.5f}, p-value = {1:.5f}'.format(k2, p)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "RAIN: k2 = 7995.34478, p-value = 0.00000\n",
        "NO RAIN: k2 = 28009.07645, p-value = 0.00000\n"
       ]
      }
     ],
     "prompt_number": 25
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Equal means - Welch's t-test"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<p>\n",
      "In <a href=\"0.%20Exploring%20data.ipynb\" target=\"_blank\">section 0</a> we already got the stats of hourly entries (every 4 hours) for rainy and non-rainy days:\n",
      "</p>\n",
      "<p>\n",
      "Hourly entries - rain: Count = 9,585, Total = 19,440,259, Median = 939, Mean = 2,028.20<br/>\n",
      "Hourly entries - no rain: Count = 33,064, Total = 61,020,916, Median = 893, Mean = 1,845.54\n",
      "</p>\n",
      "<p>\n",
      "Median and mean are both a bit higher for rainy days. But are they statistically higher than non-rainy days? Though when we perform Welch's t-test we usually assume the data is normal, with large enough sample size, we can still run Welch's t-test to see if 2 data sets have the same sample means (&mu;<sub>1</sub> = &mu;<sub>2</sub>). Welch's t-test doesn't assume equal sample size nor equal variance. Below the scipy.stats.ttest_ind function returns a 2-tail p-value, which is much smaller than p-critical 0.025. We can reject the ull hypothesis that 2 independent samples have identical average (expected) values. Here t-statistic is greater than 0 and 1-tail p-value/2 is much less than p-critical 0.025. We can confirm that the mean of entries is significantly higher when it rained (&mu;<sub>1</sub> &gt; &mu;<sub>2</sub>). This is interesting. From the bar chart in <a href=\"0.%20Exploring%20data.ipynb\" target=\"_blank\">section 0</a> these 2 data sets don't look too different but they are statistically different.\n",
      "</p>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "t, p = st.ttest_ind(ent_hr_rain, ent_hr_no_rain, equal_var = False)\n",
      "print '2-tail RAIN vs. NO RAIN: t = {0:,.5f}, p-value = {1:.10f}'.format(t, p)\n",
      "print '1-tail RAIN vs. NO RAIN: p-value/2 = {0:.10f}'.format(p/2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "2-tail RAIN vs. NO RAIN: t = 5.04288, p-value = 0.0000004641\n",
        "1-tail RAIN vs. NO RAIN: p-value/2 = 0.0000002321\n"
       ]
      }
     ],
     "prompt_number": 26
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "One way to check how much the factor could affect the results is by calculating a R^2 = t^2 / (t^2 + Degree of Freedom). And the result shows that only about 0.06% of the differences in ridership was due to rain. Though the ridership was statistically higher for rainy days, some other factors are playing important roles too."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "r_squared = t*t / (t*t + (9585 + 33064 - 2))\n",
      "print 'R^2 = t^2 / (t^2 + Degree of Freedom) = {}'.format(r_squared)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "R^2 = t^2 / (t^2 + Degree of Freedom) = 0.00059595073468\n"
       ]
      }
     ],
     "prompt_number": 27
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Same populations - Mann\u2013Whitney U test"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Since the data is non-normal, we can try Mann\u2013Whitney U test which is a nonparametric test of the null hypothesis that two populations are the same. Mann\u2013Whitney U test doesn't assume any underlying probability distribution. Below I'm running scipy.stats.mannwhitneyu function to see if these 2 data sets are from the same population. This function returns a 1-tail p-value."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "u, p = st.mannwhitneyu(ent_hr_rain, ent_hr_no_rain)\n",
      "print '1-tail RAIN vs. NO RAIN: u = {0:,.2f}, p-value = {1:.10f}'.format(u, p)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1-tail RAIN vs. NO RAIN: u = 153,635,120.50, p-value = nan\n"
       ]
      }
     ],
     "prompt_number": 28
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "However, I can't get p-value directly using this function. So below I'm calculating p-value maually, following the steps for normal approximation provided in http://en.wikipedia.org/wiki/Mann%E2%80%93Whitney_U_test#Normal_approximation.<img src=\"mwu2.JPG\"/><img src=\"mwu3.JPG\"/><img src=\"mwu1.JPG\"/> This test is often performed as a 2-tail test, thus, the research hypothesis indicates that the populations are not equal as opposed to specifying directionality. Below I'm converting it to 2-tail p-value which is much less than p-critical 0.05. And we can reject the null hypothesis that two populations are the same. Ridership of raining and non-raining days are different."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "m_u = len(ent_hr_rain) * len(ent_hr_no_rain) / 2\n",
      "print \"m_u = {0:,.1f}\".format(m_u)\n",
      "sigma_u = np.sqrt(len(ent_hr_rain) * len(ent_hr_no_rain) * (len(ent_hr_rain) + len(ent_hr_no_rain) + 1) / 12)\n",
      "print \"sigma_u = {0:,.5f}\".format(sigma_u)\n",
      "z = (u - m_u) / sigma_u\n",
      "print \"z = {0:,.5f}\".format(z)\n",
      "p = 2 * st.norm.cdf(z)\n",
      "print '2-tail RAIN vs. NO RAIN: u = {0:,.2f}, 2*p-value = {1:.10f}'.format(u, p)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "m_u = 158,459,220.0\n",
        "sigma_u = 1,061,310.96079\n",
        "z = -4.54542\n",
        "2-tail RAIN vs. NO RAIN: u = 153,635,120.50, 2*p-value = 0.0000054827\n"
       ]
      }
     ],
     "prompt_number": 29
    }
   ],
   "metadata": {}
  }
 ]
}